{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import sys  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os, shutil\n",
    "from shutil import copyfile\n",
    "import copy\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "import csv\n",
    "import random\n",
    "import pathlib\n",
    "import cProfile\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, mean_absolute_error\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from datetime import date\n",
    "import numpy\n",
    "from keras.utils import plot_model\n",
    "import pickle\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Model\n",
    "from keras.layers import Convolution2D, Activation, GlobalAveragePooling2D, Reshape, Dropout, Dense, ReLU\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenetv2_transfer_learning(num_classes):\n",
    "    ft_layers = [2]\n",
    "    mobilenet = keras.applications.MobileNetV2()\n",
    "    x = mobilenet.layers[-3].output\n",
    "\n",
    "    x = Convolution2D(64, (3, 3), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5, name='dropout')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax', name='re_lu_1/Relu6')(x)\n",
    "\n",
    "    model = Model(inputs=mobilenet.input, outputs=predictions)\n",
    "\n",
    "    print(model.summary())\n",
    "    return model, ft_layers\n",
    "\n",
    "def fine_tune(model, ft_depth):\n",
    "    for layer in model.layers[-ft_depth:]:\n",
    "        layer.trainable = True\n",
    "    for layer in model.layers[:-ft_depth]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Show which layers are now trainable\n",
    "    for layer in model.layers:\n",
    "        if layer.trainable:\n",
    "            print(layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function taking in two numpy nd-arrays (predictions & true labels) and outputing the accuracies (raw accuracy,\n",
    "### off-by-1 accuracy, off-by-2 accuracy) ###\n",
    "def getAccuracy(preds, labels):\n",
    "    rightPredCount = 0 ## counter for right predictions\n",
    "    offBy1Count = 0 ## counter for off-by-1 predictions\n",
    "    offBy2Count = 0 ## counter for off-by-2 predictions\n",
    "    accDico = {\n",
    "        \"correctPredictions\": '', \n",
    "        \"raw accuracy\": '',\n",
    "        \"offBy1Predictions\":'',\n",
    "        \"offBy1acc\": '',\n",
    "        \"offBy2Predictions\":'',\n",
    "        \"offBy2acc\": ''\n",
    "    }\n",
    "    if len(preds) != len(labels):\n",
    "        raise ValueError(\"Arrays must have the same size\")\n",
    "        return\n",
    "    else:\n",
    "        for i in range(len(preds)): # iterate through arrays\n",
    "            if preds[i] == labels[i]: # correct prediction\n",
    "                rightPredCount += 1\n",
    "            elif abs( preds[i] - labels[i] ) == 1:\n",
    "                offBy1Count += 1\n",
    "            elif abs( preds[i] - labels[i] ) == 2:\n",
    "                offBy2Count += 1\n",
    "            else:\n",
    "                bs = 0 # do nothing\n",
    "    rawAcc = float( rightPredCount / len(preds) )\n",
    "    offBy1acc = float( (rightPredCount + offBy1Count) / len(preds) )\n",
    "    offBy2acc = float( (rightPredCount + offBy1Count + offBy2Count) / len(preds) )\n",
    "    accDico['correctPredictions'] = rightPredCount\n",
    "    accDico['raw accuracy'] = rawAcc\n",
    "    accDico['offBy1Predictions'] = offBy1Count\n",
    "    accDico['offBy1acc'] = offBy1acc\n",
    "    accDico['offBy2Predictions'] = offBy2Count\n",
    "    accDico['offBy2acc'] = offBy2acc\n",
    "    return accDico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numImagesTotal():\n",
    "    notebook_path = os.path.dirname(os.path.realpath('__file__'))\n",
    "    streetViewData_dir = \"/GoogleStreetView_images/labelled_data_already_scp-ed\"\n",
    "    path = notebook_path + streetViewData_dir\n",
    "    print(path)\n",
    "    dirs = os.listdir(path)\n",
    "    dirs.sort()\n",
    "    totalNumImages = 0\n",
    "    sizesPerLabel = {}\n",
    "    for k in dirs:\n",
    "        path2 = path + '/' + k\n",
    "        files = os.listdir(path2)\n",
    "        sizesPerLabel[k] = len(files)\n",
    "        totalNumImages += len(files)\n",
    "    print(sizesPerLabel)\n",
    "    print(\"Total number of images in the directory: \", totalNumImages)\n",
    "    print(\"---\")\n",
    "    return path, totalNumImages, sizesPerLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'GoogleStreetView_images/3datasets/train'\n",
    "val_path   = 'GoogleStreetView_images/3datasets/val'\n",
    "test_path  = 'GoogleStreetView_images/new_test_set-never_seen'\n",
    "notebook_path = os.path.dirname(os.path.realpath('__file__'))\n",
    "os.path.isdir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4874 images belonging to 8 classes.\n",
      "Found 1214 images belonging to 8 classes.\n",
      "Found 787 images belonging to 8 classes.\n",
      "8\n",
      "4874\n"
     ]
    }
   ],
   "source": [
    "### create batches ###\n",
    "preprocess=True\n",
    "class_mode=\"categorical\"\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "if preprocess:\n",
    "    preprocess_fn = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "else:\n",
    "    preprocess_fn=None\n",
    "    \n",
    "train_batches = ImageDataGenerator(preprocessing_function=preprocess_fn).flow_from_directory(train_path, \n",
    "                                                         target_size=(224,224), \n",
    "                                                         classes=['0','1','2','3','4','5','6','7'], batch_size=64,\n",
    "                                                                                            class_mode=class_mode)   \n",
    "val_batches = ImageDataGenerator(preprocessing_function=preprocess_fn).flow_from_directory(val_path, \n",
    "                                                         target_size=(224,224), \n",
    "                                                         classes=['0','1','2','3','4','5','6','7'], batch_size=32,\n",
    "                                                                                          class_mode=class_mode)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=preprocess_fn).flow_from_directory(test_path, \n",
    "                                                         target_size=(224,224), \n",
    "                                                         classes=['0','1','2','3','4','5','6','7'], batch_size=64,\n",
    "                                                                                           class_mode=class_mode)\n",
    "print(train_batches.num_classes)\n",
    "print(train_batches.samples)\n",
    "\n",
    "steps_per_epoch = train_batches.samples // train_batches.batch_size\n",
    "validation_steps = val_batches.samples // val_batches.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## START ##\n",
    "IMG_SIZE = (224, 224)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "print(IMG_SHAPE)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(8, activation='softmax', name=\"act_softmax\")\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL ###\n",
    "print(IMG_SHAPE)\n",
    "inputs = base_model.input # base_model is MobileNetV2 pretrained on Imagenet\n",
    "x = base_model(inputs, training=True) # use training=False as our model contains a BatchNormalization layer\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model ##\n",
    "import pydot\n",
    "import pydotplus\n",
    "notebook_path = os.path.dirname(os.path.realpath('__file__'))\n",
    "print(os.path.isdir(notebook_path + '/model/architecture/'))\n",
    " \n",
    "model_visual_fp = notebook_path + '/graph/'+ 'mobilenetv2' + '.png'\n",
    "print(\"Saving model visual to file: \"+ model_visual_fp)\n",
    "if not os.path.isdir(notebook_path + '/graph'):\n",
    "    os.mkdir(notebook_path + '/graph')\n",
    "tf.keras.utils.plot_model(model, to_file=model_visual_fp, show_shapes=True)\n",
    "\n",
    "## Saving the architecture / configuration only (explicit graphs of layers)\n",
    "architecture_fp = notebook_path + \"/model/architecture/\"+ 'mobilenetv2' + '.json'\n",
    "print(\"Saving model architecture to file: \"+architecture_fp)\n",
    "model_json_config = model.to_json()\n",
    "with open(architecture_fp, \"w\") as json_file:\n",
    "    json.dump(model_json_config, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## checkpoint & training ##\n",
    "if not os.path.isdir(notebook_path + '/model/weights'):\n",
    "    os.mkdir(notebook_path + '/model/weights')\n",
    "checkpoint_filepath = notebook_path + '/model/weights/'\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath + 'mobilenetv2' + '-{epoch:02d}-{val_acc:.2f}.hdf5',\n",
    "        monitor='val_acc',\n",
    "        verbose=1, \n",
    "        save_weights_only=True,\n",
    "        save_best_only=True, \n",
    "        mode='max'\n",
    "    )\n",
    "\n",
    "total_epochs = 15\n",
    "start_time = time.time()\n",
    "print(\"Program starts at time: \",start_time)\n",
    "\n",
    "history = model.fit_generator(train_batches,\n",
    "                         epochs=total_epochs,\n",
    "                         steps_per_epoch=steps_per_epoch,\n",
    "                         validation_data=val_batches,\n",
    "                         validation_steps=validation_steps,\n",
    "                         callbacks=[model_checkpoint]\n",
    "                        )  \n",
    "end_time = time.time()\n",
    "print(\"Program ends at time\",end_time) \n",
    "total_time = (end_time - start_time) \n",
    "print(\"Total time elapsed in training(s): \" +str(\"%.3f\" %total_time))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save history ##\n",
    "print(\"Saving history to file\")\n",
    "notebook_path = os.path.dirname(os.path.realpath('__file__'))\n",
    " \n",
    "if not os.path.isdir(notebook_path + '/graph'):\n",
    "    os.mkdir('./graph')\n",
    "with open('./graph/history_RUN'+ '.pkl','wb') as f:\n",
    "    pickle.dump(history.history,f)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import graph_io, graph_util\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = os.path.dirname(os.path.realpath('__file__'))\n",
    "RUN_ID = 3\n",
    "# refer to train_result.json\n",
    "architecture_fp = notebook_path +'/model/architecture/mobilenetv2.json'\n",
    "weights_fp = notebook_path +'/model/weights/mobilenetv2-02-0.57.hdf5'\n",
    "save_fp = notebook_path + '/model/saved_pb/'+'run' + str(RUN_ID)+\".pb\"\n",
    "model_type = 'V2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START SESSION & LOAD MODEL ###\n",
    "sess = tf.Session()\n",
    "final_layer = 'act_softmax/Softmax'\n",
    "with open(architecture_fp,'r') as f:\n",
    "    model_json = json.load(f)\n",
    "print(final_layer)\n",
    "model = tf.keras.models.model_from_json(model_json)\n",
    "model.load_weights(weights_fp)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = keras.backend.get_session()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "# session = K.get_session()\n",
    "minimal_graph = graph_util.convert_variables_to_constants(session, session.graph.as_graph_def(), [final_layer])\n",
    "print(\"Saving to: \" + save_fp)\n",
    "graph_io.write_graph(minimal_graph, '.', save_fp, as_text=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
